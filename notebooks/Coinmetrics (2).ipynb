{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdblp as bbg\n",
    "from sklearn import preprocessing as pp\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import yellowbrick\n",
    "import requests\n",
    "import json\n",
    "print(tf.__version__)\n",
    "from yellowbrick.features import RadViz, Rank2D, Rank1D, ParallelCoordinates\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def scatter_plot(data, feature, target):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.scatter(data[feature], \n",
    "                data[target],\n",
    "                c='black'\n",
    "    )\n",
    "    plt.xlabel(f'Feature = {feature}')\n",
    "    plt.ylabel(f'Target = {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def get_coin_metrics_assets():\n",
    "    coin_metrics_session = requests.Session()\n",
    "    coin_metrics_url = 'https://api.coinmetrics.io/v2/assets?'\n",
    "    coin_metrics_api_key = '&api_key=DlgTDcpDmRS8H5gNnila' #append to every request\n",
    "    response = coin_metrics_session.get(coin_metrics_url + coin_metrics_api_key, verify=False)\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def get_coin_metrics_asset_info(asset_id):\n",
    "    coin_metrics_session = requests.Session()\n",
    "    coin_metrics_url = f'https://api.coinmetrics.io/v2/assets/{asset_id}'\n",
    "    coin_metrics_api_key = '?api_key=DlgTDcpDmRS8H5gNnila' #append to every request\n",
    "    #print(coin_metrics_url + coin_metrics_api_key)\n",
    "    response = coin_metrics_session.get(coin_metrics_url + coin_metrics_api_key, verify=False)\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def get_coin_metrics_metrics():\n",
    "    coin_metrics_session = requests.Session()\n",
    "    coin_metrics_url = 'https://api.coinmetrics.io/v2/metric?'\n",
    "    coin_metrics_api_key = '&api_key=DlgTDcpDmRS8H5gNnila' #append to every request\n",
    "    response = coin_metrics_session.get(coin_metrics_url + coin_metrics_api_key, verify=False)\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def get_coin_metrics_data(asset_id, metrics):\n",
    "    coin_metrics_session = requests.Session()\n",
    "    coin_metrics_url = f'https://api.coinmetrics.io/v2/assets/{asset_id}/metricdata?'\n",
    "    coin_metrics_api_key = 'api_key=DlgTDcpDmRS8H5gNnila' #append to every request\n",
    "    query_string = f'&metrics={metrics}'\n",
    "    print(coin_metrics_url + coin_metrics_api_key + query_string)\n",
    "    response = coin_metrics_session.get(coin_metrics_url + coin_metrics_api_key + query_string, verify=False)\n",
    "    #print(response.text)\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {},
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(get_coin_metrics_assets())\n",
    "assets = list(df.assets.values)\n",
    "for a in ['btc']: #assets[0:1]:\n",
    "    asset_data = pd.DataFrame(get_coin_metrics_asset_info(a))\n",
    "    for x in asset_data[0:1]:\n",
    "        metrics = pd.DataFrame(get_coin_metrics_data(asset_data[x].id, ','.join(list(asset_data[x].metrics)))).reset_index()\n",
    "        print(asset_data[x].id)\n",
    "        time_series = pd.DataFrame(columns=metrics[metrics['index']=='metrics']['metricData'][0])\n",
    "        x = pd.DataFrame(metrics[metrics['index']=='series'])['metricData'].values\n",
    "        times = []\n",
    "        for z in [k for k in x[0]]:\n",
    "            for y,v in z.items():\n",
    "                if isinstance(v, str):\n",
    "                    times.append(v)\n",
    "                else:\n",
    "                    time_series.loc[len(time_series)] = v\n",
    "                    \n",
    "        time_series['times'] = times\n",
    "        time_series['OneDayReturn'] = time_series.PriceUSD.astype('float').pct_change(1)\n",
    "        time_series.loc[0, 'NextDayReturn'] =  time_series.loc[0, 'OneDayReturn']\n",
    "        for i in range(1, len(time_series)):\n",
    "            try:\n",
    "                time_series.loc[i, 'NextDayReturn'] = time_series.loc[i+1, 'OneDayReturn']\n",
    "            except:\n",
    "                time_series.loc[i, 'NextDayReturn'] = 0\n",
    "        print(time_series[['times', 'OneDayReturn', 'NextDayReturn']].tail(50))\n",
    "        relevant_features = ['AdrActCnt', 'CapAct1yrUSD', 'CapRealUSD', 'CapMVRVCur', \n",
    "                        'HashRate', 'SplyAct1yr', 'NVTAdj', 'NVTAdj90','TxCnt', 'TxTfr','TxTfrValAdjUSD', \n",
    "                        'TxTfrValUSD', 'TxTfrValDayDst', 'TxTfrValDayDstMean' ,'UTXOCnt', 'VelActAdj1yr', 'VelCurAdj1yr']\n",
    "        for feature in relevant_features:\n",
    "            time_series[feature] = time_series[feature].astype('float64')\n",
    "            if time_series[feature].dtype == np.dtype('float64'):\n",
    "                time_series[feature + '_SCALED'] = scale(pp.scale, time_series[feature])\n",
    "                scatter_plot(time_series, feature + '_SCALED', 'NextDayReturn')\n",
    "                for lag in range(1,3):\n",
    "                    time_series[feature + f'_{lag}_DAY_LAG'] = time_series[feature].pct_change(lag)\n",
    "                    scatter_plot(time_series, feature + f'_{lag}_DAY_LAG', 'NextDayReturn')\n",
    "            #else:\n",
    "            #    scatter_plot(time_series, feature, 'OneDayReturn')\n",
    "    time_series.drop(columns=relevant_features + ['times'], inplace=True)\n",
    "    time_series.replace([np.nan, np.inf, -np.inf], 0, inplace=True)\n",
    "    print(time_series.describe())\n",
    "     \n",
    "    [errors, linear_model, score, intercept] = run_linear_regression(time_series, 'NextDayReturn')\n",
    "    print(linear_model.get_params(deep=True))\n",
    "    print(errors)\n",
    "    print(score)\n",
    "    print(intercept)\n",
    "#relevant_metrics = ['TransferValueAdjusted/Raw', 'txCounts', 'UTXO', 'ActiveAddresses', 'NVT (Ratio of Price to Transaction Volume)'\n",
    "#macro cycle? Current?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Configure Data Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def encode(encoder, data, reshape=False):\n",
    "    if reshape:\n",
    "        data = np.array(data).reshape(-1,1) #do not reshape for label encoding, reshape for to 1D array for OHE\n",
    "    return encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def scale(scaler, data):\n",
    "    return scaler(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(data, target):\n",
    "    Xs = data.drop([target], axis=1)\n",
    "    y = data[target].values.reshape(-1, 1)\n",
    "    lin_reg = LinearRegression().fit(Xs, y)\n",
    "    MSEs = cross_val_score(lin_reg, Xs, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    score = lin_reg.score(Xs, y)\n",
    "    #lin_reg = lin_reg.fit(Xs, y)\n",
    "    return MSEs, lin_reg, score, lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ridge_regression(data, target, alphas={'alpha':[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}):\n",
    "    Xs = data.drop([target], axis=1)\n",
    "    y = data[target].values.reshape(-1, 1)\n",
    "    ridge = Ridge()\n",
    "    ridge_regression = GridSearchCV(ridge, alphas, scoring='neg_mean_squared_error', cv=5)\n",
    "    ridge_regression.fit(Xs, y)\n",
    "    print(ridge_regression.best_params_)\n",
    "    print(ridge_regression.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lasso_regression(data, target, alphas={'alpha':[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}):\n",
    "    Xs = data.drop([target], axis=1)\n",
    "    y = data[target].values.reshape(-1, 1)\n",
    "    lasso = Lasso()\n",
    "    lasso_regression = GridSearchCV(lasso, alphas, scoring='neg_mean_squared_error', cv=5)\n",
    "    lasso_regression.fit(Xs, y)\n",
    "    print(lasso_regression.best_params_)\n",
    "    print(lasso_regression.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
